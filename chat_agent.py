from langchain_ollama import OllamaLLM
from load_data import load_clients, load_factures, load_paiements, load_clients_data

llm = OllamaLLM(model="llama3")

def summarize_data():
    clients = load_clients()
    factures = load_factures()
    paiements = load_paiements()
    historique = load_clients_data()

    client_summary = "\n".join([
        f"- {row['id']} | {row['name']} | {row['email']}" for _, row in clients.iterrows()
    ])

    facture_summary = "\n".join([
        f"- Facture {row['id']} | Client {row['client_id']} | Montant {row['amount']}â‚¬ | Ã‰chÃ©ance {row['date_due']} | Statut {row['status']}"
        for _, row in factures.iterrows()
    ])

    paiement_summary = "\n".join([
        f"- Paiement {row['id']} | Facture {row['facture_id']} | Montant {row['amount']}â‚¬ | Date {row['date']}"
        for _, row in paiements.iterrows()
    ])

    risque_summary = "\n".join([
        f"- {row['name']} : {row['nombre_de_facture_impayÃ©es']} impayÃ©es sur {row['nombre_total_de_factures']} ({row['pourcentage_de_factures_impayÃ©es']}%)"
        for _, row in historique.iterrows()
    ])

    return client_summary, facture_summary, paiement_summary, risque_summary


def chat_with_agent(message: str) -> str:
    clients, factures, paiements, risques = summarize_data()

    prompt = f"""
Tu es un assistant comptable intelligent. Utilise les donnÃ©es suivantes pour rÃ©pondre aux questions posÃ©es.

ğŸ“‹ Clients :
{clients}

ğŸ“„ Factures :
{factures}

ğŸ’° Paiements :
{paiements}

ğŸ“Š Risques :
{risques}

Maintenant, rÃ©ponds Ã  cette question de maniÃ¨re claire, concise et professionnelle :
\"{message}\"
"""
    return llm.invoke(prompt)
